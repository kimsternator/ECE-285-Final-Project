{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea700391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d6983",
   "metadata": {},
   "source": [
    "# Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n",
    "\n",
    "data_url = \"./Data/VGG Data/DATA\"\n",
    "train_url = \"./Data/VGG Data/Train\"\n",
    "test_url = \"./Data/VGG Data/Test\"\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "for class_label in os.listdir(data_url):\n",
    "    images = os.listdir(f\"{data_url}/{class_label}\")\n",
    "    random.shuffle(images)\n",
    "    split_index = int(len(images) * test_size)\n",
    "    \n",
    "    for image in images[:split_index]:\n",
    "        class_url = f\"{test_url}/{str(class_label)}\"\n",
    "\n",
    "        if not os.path.exists(class_url):\n",
    "            os.mkdir(class_url)\n",
    "    \n",
    "        old_image_url = f\"{data_url}/{class_label}/{image}\"\n",
    "        new_image_url = f\"{test_url}/{class_label}/{image}\"\n",
    "        shutil.move(old_image_url, new_image_url)\n",
    "        \n",
    "    for image in images[split_index:]:\n",
    "        class_url = f\"{train_url}/{str(class_label)}\"\n",
    "\n",
    "        if not os.path.exists(class_url):\n",
    "            os.mkdir(class_url)\n",
    "    \n",
    "        old_image_url = f\"{data_url}/{class_label}/{image}\"\n",
    "        new_image_url = f\"{train_url}/{class_label}/{image}\"\n",
    "        shutil.move(old_image_url, new_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5318e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speed limit (5km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speed limit (15km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speed limit (30km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speed limit (40km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Speed limit (50km/h)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClassId                  Name\n",
       "0        0   Speed limit (5km/h)\n",
       "1        1  Speed limit (15km/h)\n",
       "2        2  Speed limit (30km/h)\n",
       "3        3  Speed limit (40km/h)\n",
       "4        4  Speed limit (50km/h)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_URL = \"./Data/labels.csv\"\n",
    "\n",
    "labels = pd.read_csv(label_URL)\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_URL = \"./Data/Test/\"\n",
    "\n",
    "sizes = set()\n",
    "\n",
    "for class_label in os.listdir(test_URL):\n",
    "    if not os.path.isdir(test_URL + class_label):\n",
    "        continue\n",
    "    for image in os.listdir(test_URL + class_label):\n",
    "        sizes.add(Image.open(test_URL + class_label + \"/\" + image).size)\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56feaa3",
   "metadata": {},
   "source": [
    "# Models\n",
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c8ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "\n",
    "target_size = (128, 128)\n",
    "num_classes = 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca77a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(input_shape=(128,128,3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    \n",
    "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    \n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    \n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "]\n",
    "\n",
    "classifier_layers = [\n",
    "    Flatten(),\n",
    "    Dense(units=4096, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=4096, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=num_classes, activation=\"softmax\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198446cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 4, 4, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                237626    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,292,154\n",
      "Trainable params: 17,018,938\n",
      "Non-trainable params: 48,273,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = Sequential()\n",
    "\n",
    "for layer in feature_layers:\n",
    "    vgg16.add(layer)\n",
    "    \n",
    "vgg16.load_weights(\"./Pretrained Models/VGG16.h5\")\n",
    "\n",
    "for layer in classifier_layers:\n",
    "    vgg16.add(layer)\n",
    "\n",
    "for layer in vgg16.layers[:-3]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d38b1",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d7f619c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 58\n",
    "resnet50_pretrained_weights_url = \"./Pretrained Models/ResNet50.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9430eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, channel_in, channel_mid, channel_out, padding=1, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channel_in, channel_mid, kernel_size=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channel_mid)\n",
    "        self.conv2 = nn.Conv2d(channel_mid, channel_mid, kernel_size=(3, 3), stride=stride, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channel_mid)\n",
    "        self.conv3 = nn.Conv2d(channel_mid, channel_out, kernel_size=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(channel_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 =  nn.Conv2d(3, 64, kernel_size=(7, 7), stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self.make_layer(64, 64, 256, 3)\n",
    "        self.layer2 = self.make_layer(256, 128, 512, 4, stride=2)\n",
    "        self.layer3 = self.make_layer(512, 256, 1024, 6, stride=2)\n",
    "        self.layer4 = self.make_layer(1024, 512, 2048, 3, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, 1000)\n",
    "        \n",
    "    def make_layer(self, channel_in, channel_mid, channel_out, num_blocks, stride=1):\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(channel_in, channel_out, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(channel_out)\n",
    "        )\n",
    "        layers = [\n",
    "            Bottleneck(channel_in, channel_mid, channel_out, stride=stride, downsample=downsample)\n",
    "        ]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(\n",
    "                Bottleneck(channel_out, channel_mid, channel_out)\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f9f0881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "           Conv2d-10            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-11            [-1, 256, 8, 8]             512\n",
      "           Conv2d-12            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-13            [-1, 256, 8, 8]             512\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-17             [-1, 64, 8, 8]             128\n",
      "             ReLU-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
      "           Conv2d-21            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
      "             ReLU-23            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-24            [-1, 256, 8, 8]               0\n",
      "           Conv2d-25             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-26             [-1, 64, 8, 8]             128\n",
      "             ReLU-27             [-1, 64, 8, 8]               0\n",
      "           Conv2d-28             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-29             [-1, 64, 8, 8]             128\n",
      "           Conv2d-30            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-31            [-1, 256, 8, 8]             512\n",
      "             ReLU-32            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-33            [-1, 256, 8, 8]               0\n",
      "           Conv2d-34            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-35            [-1, 128, 8, 8]             256\n",
      "             ReLU-36            [-1, 128, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-38            [-1, 128, 4, 4]             256\n",
      "           Conv2d-39            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-43            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-44            [-1, 512, 4, 4]               0\n",
      "           Conv2d-45            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
      "             ReLU-47            [-1, 128, 4, 4]               0\n",
      "           Conv2d-48            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-49            [-1, 128, 4, 4]             256\n",
      "           Conv2d-50            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-51            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-52            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-53            [-1, 512, 4, 4]               0\n",
      "           Conv2d-54            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-55            [-1, 128, 4, 4]             256\n",
      "             ReLU-56            [-1, 128, 4, 4]               0\n",
      "           Conv2d-57            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-58            [-1, 128, 4, 4]             256\n",
      "           Conv2d-59            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-61            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-64            [-1, 128, 4, 4]             256\n",
      "             ReLU-65            [-1, 128, 4, 4]               0\n",
      "           Conv2d-66            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-67            [-1, 128, 4, 4]             256\n",
      "           Conv2d-68            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-69            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-70            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-71            [-1, 512, 4, 4]               0\n",
      "           Conv2d-72            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-73            [-1, 256, 4, 4]             512\n",
      "             ReLU-74            [-1, 256, 4, 4]               0\n",
      "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
      "           Conv2d-77           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-78           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-79           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-80           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-81           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-82           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-83            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-84            [-1, 256, 2, 2]             512\n",
      "             ReLU-85            [-1, 256, 2, 2]               0\n",
      "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
      "           Conv2d-88           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-90           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-91           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-92            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-93            [-1, 256, 2, 2]             512\n",
      "             ReLU-94            [-1, 256, 2, 2]               0\n",
      "           Conv2d-95            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-96            [-1, 256, 2, 2]             512\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "          Conv2d-106           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-107           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-108           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-109           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-110            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-111            [-1, 256, 2, 2]             512\n",
      "            ReLU-112            [-1, 256, 2, 2]               0\n",
      "          Conv2d-113            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-114            [-1, 256, 2, 2]             512\n",
      "          Conv2d-115           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-116           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-117           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-118           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-119            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-120            [-1, 256, 2, 2]             512\n",
      "            ReLU-121            [-1, 256, 2, 2]               0\n",
      "          Conv2d-122            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-123            [-1, 256, 2, 2]             512\n",
      "          Conv2d-124           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-125           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-126           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-127           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-128            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-129            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-130            [-1, 512, 2, 2]               0\n",
      "          Conv2d-131            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-132            [-1, 512, 1, 1]           1,024\n",
      "          Conv2d-133           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-134           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-135           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-136           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-137           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-138           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-139            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-140            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-141            [-1, 512, 1, 1]               0\n",
      "          Conv2d-142            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-143            [-1, 512, 1, 1]           1,024\n",
      "          Conv2d-144           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-145           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-146           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-147           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-148            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-149            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-150            [-1, 512, 1, 1]               0\n",
      "          Conv2d-151            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-152            [-1, 512, 1, 1]           1,024\n",
      "          Conv2d-153           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-155           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-156           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 2048, 1, 1]               0\n",
      "          Linear-158                   [-1, 58]         118,842\n",
      "================================================================\n",
      "Total params: 23,626,874\n",
      "Trainable params: 118,842\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.65\n",
      "Params size (MB): 90.13\n",
      "Estimated Total Size (MB): 95.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "resnet50 = ResNet50()\n",
    "\n",
    "resnet50.load_state_dict(torch.load(resnet50_pretrained_weights_url))\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "resnet50.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "summary(resnet50.to(\"cuda\"), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dbea6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996bb9c",
   "metadata": {},
   "source": [
    "## LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87c8d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, AveragePooling2D, Dropout, BatchNormalization\n",
    "\n",
    "num_classes = 58\n",
    "target_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8534f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 28, 28, 6)        24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 14, 14, 6)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 10, 10, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_13 (Avera  (None, 5, 5, 16)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 58)                4930      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,874\n",
      "Trainable params: 65,830\n",
      "Non-trainable params: 44\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet5 = Sequential([   \n",
    "    Conv2D(filters=6, input_shape=(32, 32, 1), kernel_size=(5, 5), activation=\"tanh\"),\n",
    "    BatchNormalization(),\n",
    "    AveragePooling2D(2),\n",
    "    Conv2D(filters=16, kernel_size=(5, 5), activation=\"tanh\"),\n",
    "    BatchNormalization(),\n",
    "    AveragePooling2D(2),\n",
    "    Conv2D(filters=120, kernel_size=(5, 5), activation=\"tanh\"),\n",
    "    Flatten(),\n",
    "    Dense(84, activation='tanh'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "    \n",
    "lenet5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f403c2",
   "metadata": {},
   "source": [
    "# Training\n",
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2e7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176bfe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3352 images belonging to 58 classes.\n",
      "Found 818 images belonging to 58 classes.\n"
     ]
    }
   ],
   "source": [
    "train_url = \"./Data/VGG Data/Train\"\n",
    "test_url = \"./Data/VGG Data/Test\"\n",
    "batch_size = 64\n",
    "target_size = (128, 128)\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
    "    .flow_from_directory(train_url, shuffle=True, class_mode=\"categorical\", batch_size=batch_size, target_size=target_size)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
    "    .flow_from_directory(test_url, shuffle=True, class_mode=\"categorical\", batch_size=batch_size, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = vgg16.fit(\n",
    "    train_batches,\n",
    "    epochs=25,\n",
    "    verbose=2,\n",
    "    validation_data=test_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Pretrain\n",
    "'''\n",
    "{'loss': [3.525979995727539, 2.8899519443511963, 2.434882879257202, 2.1614224910736084, 1.9181642532348633, 1.7425360679626465, 1.5772042274475098, 1.4680629968643188, 1.3730199337005615, 1.2916934490203857, 1.1915274858474731, 1.1220812797546387, 1.0652923583984375, 1.0273462533950806, 0.9893081188201904, 0.9514791369438171, 0.9155832529067993, 0.8515679836273193, 0.8318435549736023, 0.7995812296867371, 0.7598579525947571, 0.7885639667510986, 0.7145692110061646, 0.6884155869483948, 0.6722703576087952], 'accuracy': [0.16557279229164124, 0.2849045395851135, 0.38007161021232605, 0.4239260256290436, 0.48359188437461853, 0.5280429720878601, 0.5638424754142761, 0.5883054733276367, 0.6172434091567993, 0.6360381841659546, 0.6587111949920654, 0.6784009337425232, 0.6837708950042725, 0.7010740041732788, 0.7058472633361816, 0.7177804112434387, 0.7228520512580872, 0.745525062084198, 0.7505966424942017, 0.7619331479072571, 0.7661097645759583, 0.7583532333374023, 0.7822195887565613, 0.7941527366638184, 0.7986276745796204], 'val_loss': [3.0600991249084473, 2.505634307861328, 2.191805839538574, 1.9498416185379028, 1.6910334825515747, 1.4788415431976318, 1.4141517877578735, 1.2690953016281128, 1.189495325088501, 1.0745114088058472, 1.0205894708633423, 0.9052702784538269, 0.884761393070221, 0.8621788620948792, 0.8151814341545105, 0.7674565315246582, 0.7320774793624878, 0.7032402157783508, 0.6263027787208557, 0.6146522164344788, 0.5949746370315552, 0.5954749584197998, 0.5730560421943665, 0.5685215592384338, 0.5240790247917175], 'val_accuracy': [0.3361858129501343, 0.43276283144950867, 0.4682151675224304, 0.48655256628990173, 0.5586796998977661, 0.6185818910598755, 0.6234718561172485, 0.6772615909576416, 0.7127139568328857, 0.738386332988739, 0.7359412908554077, 0.761613667011261, 0.790953516960144, 0.7836185693740845, 0.7762836217880249, 0.7958435416221619, 0.8117359280586243, 0.8239609003067017, 0.8484107851982117, 0.8361858129501343, 0.8569682240486145, 0.8557457327842712, 0.8728606104850769, 0.8667481541633606, 0.8765281438827515]}\n",
    "'''\n",
    "# Pretrain\n",
    "'''\n",
    "{'loss': [18.793527603149414, 1.252179741859436, 0.7609100937843323, 0.5249869227409363, 0.44329315423965454, 0.40843403339385986, 0.3812047839164734, 0.4069596827030182, 0.37956562638282776, 0.4497087001800537, 0.42380839586257935, 0.48469915986061096, 0.5351912379264832, 0.4932202100753784, 0.48433583974838257, 0.4134829342365265, 0.39266371726989746, 0.40559425950050354, 0.34826433658599854, 0.3698195517063141, 0.3830086290836334, 0.3082433342933655, 0.3518733084201813, 0.4435766041278839, 0.3689365088939667], 'accuracy': [0.546241044998169, 0.8505370020866394, 0.8758949637413025, 0.906324565410614, 0.9191527366638184, 0.9266110062599182, 0.9328758716583252, 0.9284009337425232, 0.943615734577179, 0.9316825866699219, 0.9364558458328247, 0.9295942783355713, 0.9373508095741272, 0.9406324625015259, 0.9415274262428284, 0.9486873745918274, 0.9504773020744324, 0.9555489420890808, 0.9603222012519836, 0.952565610408783, 0.9543555974960327, 0.9576372504234314, 0.9567422270774841, 0.9501789808273315, 0.9606205224990845], 'val_loss': [1.1364144086837769, 0.5852822065353394, 0.46912509202957153, 0.3824549913406372, 0.4593915641307831, 0.4409973621368408, 0.37583020329475403, 0.3581882417201996, 0.622353732585907, 0.37841796875, 0.3754598796367645, 0.4300534129142761, 0.5109768509864807, 0.37367919087409973, 0.37530601024627686, 0.6197020411491394, 0.3931267559528351, 0.5752502083778381, 0.6990096569061279, 0.40637508034706116, 0.39942750334739685, 0.6513607501983643, 0.5577841997146606, 0.6005098223686218, 0.5296468734741211], 'val_accuracy': [0.8814181089401245, 0.9107579588890076, 0.9449877738952637, 0.9572126865386963, 0.9498777389526367, 0.9486552476882935, 0.9669926762580872, 0.9706601500511169, 0.9376528263092041, 0.9731051325798035, 0.9645476937294006, 0.9621027112007141, 0.9547677040100098, 0.9657701849937439, 0.9731051325798035, 0.9547677040100098, 0.9706601500511169, 0.9718826413154602, 0.9657701849937439, 0.9743276238441467, 0.9779950976371765, 0.9706601500511169, 0.9767726063728333, 0.97555011510849, 0.97555011510849]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52319602",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8ec32ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3352 Training Images for 58 classes\n",
      "Found 818 Test Images for 58 classes\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "train_url = \"./Data/VGG Data/Train\"\n",
    "test_url = \"./Data/VGG Data/Test\"\n",
    "batch_size = 50\n",
    "num_classes = 58\n",
    "target_size = (32, 32)\n",
    "\n",
    "resize = transforms.Resize(size=target_size)\n",
    "horizontal_flip = transforms.RandomHorizontalFlip(p=0.25)\n",
    "vertical_flip = transforms.RandomVerticalFlip(p=0.25)\n",
    "rotate = transforms.RandomRotation(degrees=15)\n",
    "\n",
    "train_transforms = transforms.Compose([resize, horizontal_flip, vertical_flip, rotate, transforms.ToTensor()])\n",
    "test_transforms = transforms.Compose([resize, transforms.ToTensor()])\n",
    "\n",
    "train_data = ImageFolder(root=train_url, transform=train_transforms)\n",
    "test_data = ImageFolder(root=test_url, transform=test_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Found {len(train_dataloader.dataset)} Training Images for {len(train_data.classes)} classes\")\n",
    "print(f\"Found {len(test_dataloader.dataset)} Test Images for {len(test_data.classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a700e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
    "\n",
    "use_gpu = True\n",
    "\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "98674a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Training Loss: 0.0095 - Training Accuracy: 0.8517 - Validation Loss: 0.0018 - Validation Accuracy: 0.9108\n",
      "===================================================\n",
      "Epoch 2/25\n",
      "Training Loss: 0.0098 - Training Accuracy: 0.8842 - Validation Loss: 0.0019 - Validation Accuracy: 0.8998\n",
      "===================================================\n",
      "Epoch 3/25\n",
      "Training Loss: 0.0081 - Training Accuracy: 0.8828 - Validation Loss: 0.002 - Validation Accuracy: 0.8851\n",
      "===================================================\n",
      "Epoch 4/25\n",
      "Training Loss: 0.013 - Training Accuracy: 0.8159 - Validation Loss: 0.0027 - Validation Accuracy: 0.8533\n",
      "===================================================\n",
      "Epoch 5/25\n",
      "Training Loss: 0.0101 - Training Accuracy: 0.8652 - Validation Loss: 0.0017 - Validation Accuracy: 0.9169\n",
      "===================================================\n",
      "Epoch 6/25\n",
      "Training Loss: 0.0095 - Training Accuracy: 0.8768 - Validation Loss: 0.0017 - Validation Accuracy: 0.901\n",
      "===================================================\n",
      "Epoch 7/25\n",
      "Training Loss: 0.0099 - Training Accuracy: 0.8953 - Validation Loss: 0.0014 - Validation Accuracy: 0.9254\n",
      "===================================================\n",
      "Epoch 8/25\n",
      "Training Loss: 0.0085 - Training Accuracy: 0.8881 - Validation Loss: 0.0015 - Validation Accuracy: 0.9279\n",
      "===================================================\n",
      "Epoch 9/25\n",
      "Training Loss: 0.007 - Training Accuracy: 0.901 - Validation Loss: 0.002 - Validation Accuracy: 0.9254\n",
      "===================================================\n",
      "Epoch 10/25\n",
      "Training Loss: 0.008 - Training Accuracy: 0.909 - Validation Loss: 0.0015 - Validation Accuracy: 0.9242\n",
      "===================================================\n",
      "Epoch 11/25\n",
      "Training Loss: 0.0077 - Training Accuracy: 0.9084 - Validation Loss: 0.0016 - Validation Accuracy: 0.9108\n",
      "===================================================\n",
      "Epoch 12/25\n",
      "Training Loss: 0.0077 - Training Accuracy: 0.9099 - Validation Loss: 0.0012 - Validation Accuracy: 0.9413\n",
      "===================================================\n",
      "Epoch 13/25\n",
      "Training Loss: 0.0063 - Training Accuracy: 0.9123 - Validation Loss: 0.0029 - Validation Accuracy: 0.9254\n",
      "===================================================\n",
      "Epoch 14/25\n",
      "Training Loss: 0.0071 - Training Accuracy: 0.9099 - Validation Loss: 0.0018 - Validation Accuracy: 0.9389\n",
      "===================================================\n",
      "Epoch 15/25\n",
      "Training Loss: 0.0061 - Training Accuracy: 0.9135 - Validation Loss: 0.041 - Validation Accuracy: 0.8888\n",
      "===================================================\n",
      "Epoch 16/25\n",
      "Training Loss: 0.0054 - Training Accuracy: 0.9159 - Validation Loss: 0.0041 - Validation Accuracy: 0.9254\n",
      "===================================================\n",
      "Epoch 17/25\n",
      "Training Loss: 0.0064 - Training Accuracy: 0.9203 - Validation Loss: 0.0018 - Validation Accuracy: 0.8985\n",
      "===================================================\n",
      "Epoch 18/25\n",
      "Training Loss: 0.0051 - Training Accuracy: 0.9242 - Validation Loss: 0.0014 - Validation Accuracy: 0.9315\n",
      "===================================================\n",
      "Epoch 19/25\n",
      "Training Loss: 0.0061 - Training Accuracy: 0.9189 - Validation Loss: 0.0013 - Validation Accuracy: 0.934\n",
      "===================================================\n",
      "Epoch 20/25\n",
      "Training Loss: 0.0073 - Training Accuracy: 0.9141 - Validation Loss: 0.0013 - Validation Accuracy: 0.9425\n",
      "===================================================\n",
      "Epoch 21/25\n",
      "Training Loss: 0.0061 - Training Accuracy: 0.9248 - Validation Loss: 0.0013 - Validation Accuracy: 0.9303\n",
      "===================================================\n",
      "Epoch 22/25\n",
      "Training Loss: 0.0051 - Training Accuracy: 0.9278 - Validation Loss: 0.0013 - Validation Accuracy: 0.9413\n",
      "===================================================\n",
      "Epoch 23/25\n",
      "Training Loss: 0.0045 - Training Accuracy: 0.9335 - Validation Loss: 0.0012 - Validation Accuracy: 0.9425\n",
      "===================================================\n",
      "Epoch 24/25\n",
      "Training Loss: 0.0062 - Training Accuracy: 0.9293 - Validation Loss: 0.0016 - Validation Accuracy: 0.9242\n",
      "===================================================\n",
      "Epoch 25/25\n",
      "Training Loss: 0.0051 - Training Accuracy: 0.9326 - Validation Loss: 0.0016 - Validation Accuracy: 0.9181\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "\n",
    "resnet50 = resnet50.to(device=device)  # move the model parameters to CPU/GPU\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    loss_train = 0\n",
    "    accuracy_train = 0\n",
    "    samples_train = 0\n",
    "    \n",
    "    resnet50.train(True)\n",
    "    for _, (inputs, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "        scores = resnet50(inputs)\n",
    "        _, predictions = torch.max(scores.data, 1)\n",
    "        loss = criterion(scores, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accuracy_train += torch.sum(predictions == labels.data).item()\n",
    "        loss_train += loss.item()\n",
    "        samples_train += predictions.size(0)\n",
    "\n",
    "        del inputs, labels, scores, predictions\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    history[\"loss\"].append(loss_train / len(train_dataloader.dataset))\n",
    "    history[\"accuracy\"].append(accuracy_train / samples_train)\n",
    "    \n",
    "    resnet50.train(False)\n",
    "    resnet50.eval()\n",
    "        \n",
    "    loss_validation = 0\n",
    "    accuracy_validation = 0\n",
    "    samples_validation = 0\n",
    "    \n",
    "    for _, (inputs, labels) in enumerate(test_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "        scores = resnet50(inputs)\n",
    "        _, predictions = torch.max(scores.data, 1)\n",
    "        loss = criterion(scores, labels)\n",
    "        \n",
    "        accuracy_validation += torch.sum(predictions == labels.data).item()\n",
    "        loss_validation += loss.item()\n",
    "        samples_validation += predictions.size(0)\n",
    "\n",
    "        del inputs, labels, scores, predictions\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    history[\"val_loss\"].append(loss_validation / len(train_dataloader.dataset))\n",
    "    history[\"val_accuracy\"].append(accuracy_validation / samples_validation)\n",
    "    \n",
    "    print(f'Training Loss: {round(history[\"loss\"][-1], 4)}', end=\" - \")\n",
    "    print(f'Training Accuracy: {round(history[\"accuracy\"][-1], 4)}', end=\" - \")\n",
    "    print(f'Validation Loss: {round(history[\"val_loss\"][-1], 4)}', end=\" - \")\n",
    "    print(f'Validation Accuracy: {round(history[\"val_accuracy\"][-1], 4)}')\n",
    "    print(\"===================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "57365d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.009493214173824805, 0.00983126290355918, 0.008130615021419981, 0.012979819935019659, 0.010140858617275598, 0.009539357535452148, 0.009867148829495138, 0.008546154083670751, 0.007014034807166365, 0.008028702657038528, 0.007714278266936327, 0.007679224129864026, 0.006335351269398782, 0.007056952609740607, 0.006053256963408577, 0.005443607238043535, 0.0064039000472262825, 0.005109014563031299, 0.006110850050334145, 0.007264184405435952, 0.006139210030783261, 0.005097257160094871, 0.004508701874374419, 0.0061953639342651875, 0.0050844423792953996], 'val_loss': [0.0018351973303391428, 0.0018531250187278079, 0.0019847011118060364, 0.0027013684051702585, 0.0016516506991978192, 0.001671742243349979, 0.0013728741409706046, 0.0014951299200265675, 0.0020366127609424203, 0.00147638477491735, 0.0016153565294560498, 0.0011558304863108371, 0.0029085180355427087, 0.0017747345596089569, 0.04098406808366355, 0.004142743499776202, 0.0018262280671366075, 0.0013849389359248281, 0.0013443943110865882, 0.0012713207547644016, 0.0013210206417042345, 0.0013177941657762824, 0.001162755140825786, 0.0015823986661355934, 0.0016001169180813153], 'accuracy': [0.8517303102625299, 0.8842482100238663, 0.8827565632458234, 0.8159307875894988, 0.8651551312649165, 0.8767899761336515, 0.8952863961813843, 0.888126491646778, 0.9009546539379475, 0.9090095465393795, 0.9084128878281623, 0.9099045346062052, 0.912291169451074, 0.9099045346062052, 0.9134844868735084, 0.915871121718377, 0.920346062052506, 0.9242243436754176, 0.918854415274463, 0.9140811455847255, 0.9248210023866349, 0.9278042959427207, 0.9334725536992841, 0.9292959427207638, 0.9325775656324582], 'val_accuracy': [0.910757946210269, 0.8997555012224939, 0.8850855745721271, 0.8533007334963325, 0.9168704156479217, 0.9009779951100244, 0.9254278728606357, 0.9278728606356969, 0.9254278728606357, 0.9242053789731052, 0.910757946210269, 0.941320293398533, 0.9254278728606357, 0.9388753056234719, 0.8887530562347188, 0.9254278728606357, 0.8985330073349633, 0.9315403422982885, 0.9339853300733496, 0.9425427872860636, 0.9303178484107579, 0.941320293398533, 0.9425427872860636, 0.9242053789731052, 0.9180929095354523]}\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'loss': [0.009493214173824805, 0.00983126290355918, 0.008130615021419981, 0.012979819935019659, 0.010140858617275598, 0.009539357535452148, 0.009867148829495138, 0.008546154083670751, 0.007014034807166365, 0.008028702657038528, 0.007714278266936327, 0.007679224129864026, 0.006335351269398782, 0.007056952609740607, 0.006053256963408577, 0.005443607238043535, 0.0064039000472262825, 0.005109014563031299, 0.006110850050334145, 0.007264184405435952, 0.006139210030783261, 0.005097257160094871, 0.004508701874374419, 0.0061953639342651875, 0.0050844423792953996], 'val_loss': [0.0018351973303391428, 0.0018531250187278079, 0.0019847011118060364, 0.0027013684051702585, 0.0016516506991978192, 0.001671742243349979, 0.0013728741409706046, 0.0014951299200265675, 0.0020366127609424203, 0.00147638477491735, 0.0016153565294560498, 0.0011558304863108371, 0.0029085180355427087, 0.0017747345596089569, 0.04098406808366355, 0.004142743499776202, 0.0018262280671366075, 0.0013849389359248281, 0.0013443943110865882, 0.0012713207547644016, 0.0013210206417042345, 0.0013177941657762824, 0.001162755140825786, 0.0015823986661355934, 0.0016001169180813153], 'accuracy': [0.8517303102625299, 0.8842482100238663, 0.8827565632458234, 0.8159307875894988, 0.8651551312649165, 0.8767899761336515, 0.8952863961813843, 0.888126491646778, 0.9009546539379475, 0.9090095465393795, 0.9084128878281623, 0.9099045346062052, 0.912291169451074, 0.9099045346062052, 0.9134844868735084, 0.915871121718377, 0.920346062052506, 0.9242243436754176, 0.918854415274463, 0.9140811455847255, 0.9248210023866349, 0.9278042959427207, 0.9334725536992841, 0.9292959427207638, 0.9325775656324582], 'val_accuracy': [0.910757946210269, 0.8997555012224939, 0.8850855745721271, 0.8533007334963325, 0.9168704156479217, 0.9009779951100244, 0.9254278728606357, 0.9278728606356969, 0.9254278728606357, 0.9242053789731052, 0.910757946210269, 0.941320293398533, 0.9254278728606357, 0.9388753056234719, 0.8887530562347188, 0.9254278728606357, 0.8985330073349633, 0.9315403422982885, 0.9339853300733496, 0.9425427872860636, 0.9303178484107579, 0.941320293398533, 0.9425427872860636, 0.9242053789731052, 0.9180929095354523]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075898e",
   "metadata": {},
   "source": [
    "## LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7feb2d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3352 images belonging to 58 classes.\n",
      "Found 818 images belonging to 58 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_url = \"./Data/VGG Data/Train\"\n",
    "test_url = \"./Data/VGG Data/Test\"\n",
    "batch_size = 50\n",
    "num_classes = 58\n",
    "target_size = (32, 32)\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255.).flow_from_directory(train_url, target_size=target_size, color_mode=\"grayscale\")\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale = 1./255.).flow_from_directory(test_url, target_size=target_size, color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8923f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "105/105 - 92s - loss: 2.4090 - accuracy: 0.4576 - val_loss: 2.8921 - val_accuracy: 0.3802 - 92s/epoch - 871ms/step\n",
      "Epoch 2/25\n",
      "105/105 - 5s - loss: 1.2470 - accuracy: 0.7005 - val_loss: 2.0968 - val_accuracy: 0.4315 - 5s/epoch - 45ms/step\n",
      "Epoch 3/25\n",
      "105/105 - 5s - loss: 0.8501 - accuracy: 0.7974 - val_loss: 1.0611 - val_accuracy: 0.7298 - 5s/epoch - 46ms/step\n",
      "Epoch 4/25\n",
      "105/105 - 5s - loss: 0.6194 - accuracy: 0.8538 - val_loss: 0.7266 - val_accuracy: 0.8142 - 5s/epoch - 46ms/step\n",
      "Epoch 5/25\n",
      "105/105 - 5s - loss: 0.4766 - accuracy: 0.9024 - val_loss: 0.4380 - val_accuracy: 0.9095 - 5s/epoch - 46ms/step\n",
      "Epoch 6/25\n",
      "105/105 - 5s - loss: 0.3633 - accuracy: 0.9284 - val_loss: 0.3592 - val_accuracy: 0.9144 - 5s/epoch - 46ms/step\n",
      "Epoch 7/25\n",
      "105/105 - 5s - loss: 0.2995 - accuracy: 0.9466 - val_loss: 0.2512 - val_accuracy: 0.9487 - 5s/epoch - 46ms/step\n",
      "Epoch 8/25\n",
      "105/105 - 5s - loss: 0.2286 - accuracy: 0.9555 - val_loss: 0.2037 - val_accuracy: 0.9621 - 5s/epoch - 46ms/step\n",
      "Epoch 9/25\n",
      "105/105 - 5s - loss: 0.1929 - accuracy: 0.9645 - val_loss: 0.1742 - val_accuracy: 0.9621 - 5s/epoch - 46ms/step\n",
      "Epoch 10/25\n",
      "105/105 - 5s - loss: 0.1531 - accuracy: 0.9740 - val_loss: 0.1465 - val_accuracy: 0.9756 - 5s/epoch - 46ms/step\n",
      "Epoch 11/25\n",
      "105/105 - 5s - loss: 0.1292 - accuracy: 0.9785 - val_loss: 0.1297 - val_accuracy: 0.9731 - 5s/epoch - 46ms/step\n",
      "Epoch 12/25\n",
      "105/105 - 5s - loss: 0.1071 - accuracy: 0.9848 - val_loss: 0.1142 - val_accuracy: 0.9804 - 5s/epoch - 46ms/step\n",
      "Epoch 13/25\n",
      "105/105 - 5s - loss: 0.0892 - accuracy: 0.9884 - val_loss: 0.1037 - val_accuracy: 0.9756 - 5s/epoch - 46ms/step\n",
      "Epoch 14/25\n",
      "105/105 - 5s - loss: 0.0794 - accuracy: 0.9902 - val_loss: 0.0971 - val_accuracy: 0.9780 - 5s/epoch - 46ms/step\n",
      "Epoch 15/25\n",
      "105/105 - 5s - loss: 0.0630 - accuracy: 0.9931 - val_loss: 0.0803 - val_accuracy: 0.9866 - 5s/epoch - 46ms/step\n",
      "Epoch 16/25\n",
      "105/105 - 5s - loss: 0.0576 - accuracy: 0.9925 - val_loss: 0.0764 - val_accuracy: 0.9817 - 5s/epoch - 46ms/step\n",
      "Epoch 17/25\n",
      "105/105 - 5s - loss: 0.0494 - accuracy: 0.9958 - val_loss: 0.0769 - val_accuracy: 0.9829 - 5s/epoch - 46ms/step\n",
      "Epoch 18/25\n",
      "105/105 - 5s - loss: 0.0429 - accuracy: 0.9976 - val_loss: 0.0606 - val_accuracy: 0.9890 - 5s/epoch - 46ms/step\n",
      "Epoch 19/25\n",
      "105/105 - 5s - loss: 0.0372 - accuracy: 0.9967 - val_loss: 0.0622 - val_accuracy: 0.9853 - 5s/epoch - 46ms/step\n",
      "Epoch 20/25\n",
      "105/105 - 5s - loss: 0.0311 - accuracy: 0.9973 - val_loss: 0.0698 - val_accuracy: 0.9804 - 5s/epoch - 46ms/step\n",
      "Epoch 21/25\n",
      "105/105 - 5s - loss: 0.0278 - accuracy: 0.9988 - val_loss: 0.0644 - val_accuracy: 0.9878 - 5s/epoch - 46ms/step\n",
      "Epoch 22/25\n",
      "105/105 - 5s - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.0560 - val_accuracy: 0.9853 - 5s/epoch - 46ms/step\n",
      "Epoch 23/25\n",
      "105/105 - 5s - loss: 0.0210 - accuracy: 0.9982 - val_loss: 0.0570 - val_accuracy: 0.9829 - 5s/epoch - 46ms/step\n",
      "Epoch 24/25\n",
      "105/105 - 5s - loss: 0.0209 - accuracy: 0.9991 - val_loss: 0.0537 - val_accuracy: 0.9829 - 5s/epoch - 46ms/step\n",
      "Epoch 25/25\n",
      "105/105 - 5s - loss: 0.0184 - accuracy: 0.9988 - val_loss: 0.0548 - val_accuracy: 0.9878 - 5s/epoch - 46ms/step\n"
     ]
    }
   ],
   "source": [
    "lenet5.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = lenet5.fit(\n",
    "    train_batches,\n",
    "    epochs=25,\n",
    "    verbose=2,\n",
    "    validation_data=test_batches,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fcf09d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.4090163707733154, 1.246998906135559, 0.8500944375991821, 0.6194496750831604, 0.4766201376914978, 0.36325007677078247, 0.29954662919044495, 0.22860822081565857, 0.19289346039295197, 0.15308305621147156, 0.12921340763568878, 0.10714416950941086, 0.08924271166324615, 0.07938934117555618, 0.06297250092029572, 0.057640984654426575, 0.04943648353219032, 0.042869050055742264, 0.037212107330560684, 0.031125769019126892, 0.027826787903904915, 0.025495674461126328, 0.020977916195988655, 0.020899269729852676, 0.018425533547997475], 'accuracy': [0.457637220621109, 0.7004773020744324, 0.797434389591217, 0.8538185954093933, 0.9024463295936584, 0.9284009337425232, 0.9465990662574768, 0.9555489420890808, 0.9644988179206848, 0.9740453362464905, 0.9785202741622925, 0.9847851991653442, 0.9883651733398438, 0.9901551604270935, 0.9931384325027466, 0.9925417900085449, 0.9958233833312988, 0.9976133704185486, 0.9967184066772461, 0.9973150491714478, 0.9988066554069519, 0.9985083341598511, 0.9982100129127502, 0.9991050362586975, 0.9988066554069519], 'val_loss': [2.892059803009033, 2.0967772006988525, 1.0611306428909302, 0.7265735268592834, 0.4380408227443695, 0.3591668903827667, 0.25116413831710815, 0.2036823183298111, 0.17422233521938324, 0.1465422511100769, 0.1296873241662979, 0.11422838270664215, 0.10367361456155777, 0.09712772071361542, 0.08032127469778061, 0.07639740407466888, 0.07686100900173187, 0.06060873717069626, 0.062211472541093826, 0.06978555023670197, 0.064402274787426, 0.05597684904932976, 0.05702206492424011, 0.053716663271188736, 0.0548069030046463], 'val_accuracy': [0.38019558787345886, 0.4315403401851654, 0.7298288345336914, 0.8141809105873108, 0.9095354676246643, 0.9144254326820374, 0.9486552476882935, 0.9621027112007141, 0.9621027112007141, 0.97555011510849, 0.9731051325798035, 0.980440080165863, 0.97555011510849, 0.9779950976371765, 0.9865525960922241, 0.9816625714302063, 0.9828850626945496, 0.9889975786209106, 0.9853300452232361, 0.980440080165863, 0.9877750873565674, 0.9853300452232361, 0.9828850626945496, 0.9828850626945496, 0.9877750873565674]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87825377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final\n",
    "'''\n",
    "{'loss': [2.4090163707733154, 1.246998906135559, 0.8500944375991821, 0.6194496750831604, 0.4766201376914978, 0.36325007677078247, 0.29954662919044495, 0.22860822081565857, 0.19289346039295197, 0.15308305621147156, 0.12921340763568878, 0.10714416950941086, 0.08924271166324615, 0.07938934117555618, 0.06297250092029572, 0.057640984654426575, 0.04943648353219032, 0.042869050055742264, 0.037212107330560684, 0.031125769019126892, 0.027826787903904915, 0.025495674461126328, 0.020977916195988655, 0.020899269729852676, 0.018425533547997475], 'accuracy': [0.457637220621109, 0.7004773020744324, 0.797434389591217, 0.8538185954093933, 0.9024463295936584, 0.9284009337425232, 0.9465990662574768, 0.9555489420890808, 0.9644988179206848, 0.9740453362464905, 0.9785202741622925, 0.9847851991653442, 0.9883651733398438, 0.9901551604270935, 0.9931384325027466, 0.9925417900085449, 0.9958233833312988, 0.9976133704185486, 0.9967184066772461, 0.9973150491714478, 0.9988066554069519, 0.9985083341598511, 0.9982100129127502, 0.9991050362586975, 0.9988066554069519], 'val_loss': [2.892059803009033, 2.0967772006988525, 1.0611306428909302, 0.7265735268592834, 0.4380408227443695, 0.3591668903827667, 0.25116413831710815, 0.2036823183298111, 0.17422233521938324, 0.1465422511100769, 0.1296873241662979, 0.11422838270664215, 0.10367361456155777, 0.09712772071361542, 0.08032127469778061, 0.07639740407466888, 0.07686100900173187, 0.06060873717069626, 0.062211472541093826, 0.06978555023670197, 0.064402274787426, 0.05597684904932976, 0.05702206492424011, 0.053716663271188736, 0.0548069030046463], 'val_accuracy': [0.38019558787345886, 0.4315403401851654, 0.7298288345336914, 0.8141809105873108, 0.9095354676246643, 0.9144254326820374, 0.9486552476882935, 0.9621027112007141, 0.9621027112007141, 0.97555011510849, 0.9731051325798035, 0.980440080165863, 0.97555011510849, 0.9779950976371765, 0.9865525960922241, 0.9816625714302063, 0.9828850626945496, 0.9889975786209106, 0.9853300452232361, 0.980440080165863, 0.9877750873565674, 0.9853300452232361, 0.9828850626945496, 0.9828850626945496, 0.9877750873565674]}\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
